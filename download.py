from playwright.sync_api import sync_playwright, TimeoutError as PWTimeout
from dataclasses import dataclass
from typing import Optional, Tuple
import json
import os
import subprocess
import sys
import re
import requests
import random
import importlib


def _resolve_load_dotenv():
    spec = importlib.util.find_spec("dotenv")
    if spec is None:
        def _noop():
            print("‚ö†Ô∏è  A python-dotenv csomag nincs telep√≠tve, .env f√°jlok nem ker√ºlnek bet√∂lt√©sre.")
        return _noop
    module = importlib.import_module("dotenv")
    return getattr(module, "load_dotenv", lambda: None)


load_dotenv = _resolve_load_dotenv()


load_dotenv()


def env_bool(key: str, default: bool) -> bool:
    value = os.getenv(key)
    if value is None:
        return default
    return value.strip().lower() in {"1", "true", "yes", "on"}


def env_int(key: str, default: int) -> int:
    value = os.getenv(key)
    if value is None:
        return default
    try:
        return int(value)
    except ValueError:
        print(f"‚ö†Ô∏è  √ârv√©nytelen eg√©sz sz√°m a(z) {key} v√°ltoz√≥ban, az alap√©rtelmezett √©rt√©ket haszn√°lom.")
        return default


FAVORITES_URL = os.getenv("FAVORITES_URL", "https://grok.com/imagine/favorites")
USER_AGENT = os.getenv(
    "USER_AGENT",
    "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/141.0.0.0 Safari/537.36",
)
COOKIE_FILE = os.getenv("COOKIE_FILE", "cookies.txt")
DOWNLOAD_DIR = os.getenv("DOWNLOAD_DIR", "downloads")
HEADLESS = env_bool("HEADLESS", False)
SCROLL_PAUSE_MS = env_int("SCROLL_PAUSE_MS", 800)
MAX_IDLE_SCROLL_CYCLES = env_int("MAX_IDLE_SCROLL_CYCLES", 10)
UPSCALE_TIMEOUT_MS = env_int("UPSCALE_TIMEOUT_MS", 20 * 1000)  # 20 m√°sodperc
UPSCALE_VIDEO_WIDTH = env_int("UPSCALE_VIDEO_WIDTH", 928)
MOUSE_SCROLL = env_int("MOUSE_SCROLL", 400)
MOUSE_SCROLL_JITTER_MS = env_int("MOUSE_SCROLL_JITTER_MS", 100)
WAIT_JITTER_MS = env_int("WAIT_JITTER_MS", 200)
WAIT_AFTER_CARD_SCROLL_MS = env_int("WAIT_AFTER_CARD_SCROLL_MS", 600)
WAIT_AFTER_MENU_INTERACTION_MS = env_int("WAIT_AFTER_MENU_INTERACTION_MS", 400)
WAIT_AFTER_BACK_BUTTON_MS = env_int("WAIT_AFTER_BACK_BUTTON_MS", 400)
WAIT_IDLE_LOOP_MS = env_int("WAIT_IDLE_LOOP_MS", 300)
INITIAL_PAGE_WAIT_MS = env_int("INITIAL_PAGE_WAIT_MS", 5000)
ASSET_BASE_HEADERS = {
    "accept": "image/avif,image/webp,image/apng,image/svg+xml,image/*,*/*;q=0.8",
    "accept-language": "hu-HU,hu;q=0.9,en-US;q=0.8,en;q=0.7",
    "priority": "i",
    "sec-ch-ua": '"Google Chrome";v="141", "Not?A_Brand";v="8", "Chromium";v="141"',
    "sec-ch-ua-mobile": "?0",
    "sec-ch-ua-platform": '"Windows"',
    "sec-fetch-dest": "image",
    "sec-fetch-mode": "no-cors",
    "sec-fetch-site": "same-site",
    "referer": "https://grok.com/",
}

os.makedirs(DOWNLOAD_DIR, exist_ok=True)

# Termin√°l sz√≠nez√©s egyszer≈± k√©nyelmi eszk√∂z√∂kkel (ha t√°mogatott)
USE_COLOR = sys.stdout.isatty() and os.environ.get("NO_COLOR") is None
COLOR_GRAY = "\033[90m" if USE_COLOR else ""
COLOR_RESET = "\033[0m" if USE_COLOR else ""

_FFPROBE_AVAILABLE: Optional[bool] = None

# --- UI sz√∂vegkonstansok √©s seg√©df√ºggv√©nyek ---

MORE_OPTIONS_LABELS = ["Tov√°bbi lehet≈ës√©gek", "More options"]
DOWNLOAD_BUTTON_LABELS = ["Let√∂lt√©s", "Download"]
BACK_BUTTON_LABELS = ["Vissza", "Back"]
UPSCALE_MENU_LABELS = ["Upscale video", "Vide√≥ felsk√°l√°z√°sa"]


def make_aria_selector(tag: str, labels):
    selectors = [f"{tag}[aria-label='{label}']" for label in labels]
    return ", ".join(selectors)


def build_menuitem_xpath(texts, disabled: bool):
    text_conditions = " or ".join([f"contains(normalize-space(.), '{text}')" for text in texts])
    disabled_clause = "@aria-disabled='true'" if disabled else "not(@aria-disabled)"
    return f"//div[@role='menuitem' and ({text_conditions}) and {disabled_clause}]"


MORE_OPTIONS_BUTTON_SELECTOR = make_aria_selector("button", MORE_OPTIONS_LABELS)
DOWNLOAD_BUTTON_SELECTOR = make_aria_selector("button", DOWNLOAD_BUTTON_LABELS)
BACK_BUTTON_SELECTOR = make_aria_selector("button", BACK_BUTTON_LABELS)
UPSCALE_MENU_DISABLED_XPATH = build_menuitem_xpath(UPSCALE_MENU_LABELS, disabled=True)
UPSCALE_MENU_ACTIVE_XPATH = build_menuitem_xpath(UPSCALE_MENU_LABELS, disabled=False)


# --- Seg√©df√ºggv√©nyek ---


def load_cookie_header(path: str) -> str:
    with open(path, "r", encoding="utf-8") as f:
        data = f.read().strip()
    if not data:
        raise ValueError("A cookie f√°jl √ºres!")
    return data


def cookie_header_to_list(header: str, domain: str):
    cookies = []
    for part in header.split(";"):
        part = part.strip()
        if not part or "=" not in part:
            continue
        name, value = part.split("=", 1)
        cookies.append({
            "name": name.strip(),
            "value": value.strip(),
            "domain": domain,
            "path": "/",
            "secure": True,
            "sameSite": "None"
        })
    return cookies


def wait_with_jitter(page, base_ms: int):
    page.wait_for_timeout(base_ms + random.randint(0, WAIT_JITTER_MS))


def scroll_to_load_more(page):
    print("‚¨áÔ∏è  G√∂rget√©s...")
    page.mouse.wheel(0, MOUSE_SCROLL + random.randint(0, MOUSE_SCROLL_JITTER_MS))
    wait_with_jitter(page, SCROLL_PAUSE_MS)


def click_safe_area(page):
    viewport = page.viewport_size or {"width": 1280, "height": 800}
    x = int(min(max(viewport["width"] * 0.6, 200), viewport["width"] - 80))
    y = int(min(max(viewport["height"] * 0.2, 120), viewport["height"] - 120))
    page.mouse.click(x, y)


def extract_video_source(page) -> Optional[str]:
    selectors = [
        "video#hd-video[src]",
        "video#sd-video[src]",
        "video[src]",
    ]
    for selector in selectors:
        try:
            page.wait_for_selector(selector, timeout=3000)
        except PWTimeout:
            continue

        locator = page.locator(selector)
        if locator.count() == 0:
            continue

        try:
            src = locator.first.get_attribute("src")
        except Exception:
            src = None

        if src:
            return src
    return None


@dataclass
class MediaCheckResult:
    image_path: str
    image_exists: bool
    video_path: str
    video_exists: bool
    video_width: Optional[int]


def probe_video_width(path: str) -> Optional[int]:
    global _FFPROBE_AVAILABLE

    if _FFPROBE_AVAILABLE is False:
        return None

    try:
        result = subprocess.run(
            [
                "ffprobe",
                "-v",
                "error",
                "-select_streams",
                "v:0",
                "-show_entries",
                "stream=width",
                "-of",
                "json",
                path,
            ],
            capture_output=True,
            text=True,
            check=True,
        )
    except FileNotFoundError:
        if _FFPROBE_AVAILABLE is not False:
            _FFPROBE_AVAILABLE = False
            print("‚ö†Ô∏è  ffprobe nem tal√°lhat√≥, a vide√≥k felbont√°s√°t nem tudom ellen≈ërizni ‚Äì √∫jra feldolgozom ≈ëket.")
        return None
    except subprocess.CalledProcessError:
        return None
    else:
        _FFPROBE_AVAILABLE = True

    try:
        payload = json.loads(result.stdout)
        streams = payload.get("streams", [])
        if streams:
            width_value = streams[0].get("width")
            if width_value is not None:
                return int(width_value)
    except (ValueError, KeyError, TypeError, IndexError):
        return None
    return None


def analyze_existing_media(image_filename: str) -> MediaCheckResult:
    name_without_ext, _ = os.path.splitext(image_filename)
    image_path = os.path.join(DOWNLOAD_DIR, f"grok-image-{name_without_ext}.png")
    video_path = os.path.join(DOWNLOAD_DIR, f"grok-video-{name_without_ext}.mp4")

    image_exists = os.path.exists(image_path)
    video_exists = os.path.exists(video_path)
    video_width = probe_video_width(video_path) if video_exists else None

    return MediaCheckResult(
        image_path=image_path,
        image_exists=image_exists,
        video_path=video_path,
        video_exists=video_exists,
        video_width=video_width,
    )


def decide_media_action(image_filename: str) -> Tuple[str, MediaCheckResult]:
    info = analyze_existing_media(image_filename)

    if info.image_exists and not info.video_exists:
        return "skip_image", info

    if info.video_exists:
        if info.video_width is None:
            return "process", info
        if info.video_width >= UPSCALE_VIDEO_WIDTH:
            return "skip_video", info
        return "process", info

    return "process", info


def get_filename_from_url(url: str, index: int):
    """Pr√≥b√°ljuk az URL-b≈ël kinyerni a Grok video ID-t, fallback az index."""
    m = re.search(r"([a-f0-9-]{36})", url)
    return f"{m.group(1) if m else f'video_{index + 1}'} .mp4"


def get_card_identifier(card):
    try:
        identifier = card.evaluate('el => el.querySelector("img")?.src || null')
        if identifier:
            identifier = str(identifier)
            slash_index = identifier.rfind("/")
            if slash_index != -1 and slash_index + 1 < len(identifier):
                name = identifier[slash_index + 1:]
                question_index = name.find("?")
                if question_index != -1:
                    name = name[:question_index]
                if name:
                    return name
            return identifier
    except Exception:
        print("‚ùå Hiba a vide√≥ azonos√≠t√≥ kinyer√©sekor.")
        pass
    return "No ID"


def xpath_literal(value: str) -> str:
    if "'" not in value:
        return f"'{value}'"
    if '"' not in value:
        return f'"{value}"'
    parts = value.split("'")
    concat_segments = []
    for index, segment in enumerate(parts):
        if segment:
            concat_segments.append(f"'{segment}'")
        if index != len(parts) - 1:
            concat_segments.append("\"'\"")
    return "concat(" + ", ".join(concat_segments) + ")"


def find_card_by_identifier(page, target_identifier: str):
    """Keress√ºk meg a k√°rty√°t k√∂zvetlen√ºl az img src alapj√°n, f√ºggetlen√ºl az aktu√°lis DOM sorrendt≈ël."""
    literal = xpath_literal(target_identifier)
    img_locator = page.locator(
        f"//div[contains(@class,'group/media-post-masonry-card')]//img[contains(@src, {literal})]"
    )
    if img_locator.count() == 0:
        return None
    return img_locator.first.locator("xpath=ancestor::div[contains(@class,'group/media-post-masonry-card')]").first

# --- F≈ë feldolgoz√≥ ---


def process_one_card(context, page, card, index: int, identifier: str, upscale_failures: list, download_failures: list):
    print(f"\nüé¨ {index + 1}. ({identifier}) vide√≥ feldolgoz√°sa...")

    def record_failure(reason: str):
        print(f"‚ùå Let√∂lt√©si hiba: {reason}")
        download_failures.append((identifier, reason))

    for attempt in range(2):
        try:
            card.scroll_into_view_if_needed()
            card.wait_for(state="visible", timeout=15000)
            wait_with_jitter(page, WAIT_AFTER_CARD_SCROLL_MS)
            card.click()
            print("üñ±Ô∏è  Megnyitva...")
            break
        except PWTimeout:
            if attempt == 0:
                print("‚ôªÔ∏è  A k√°rtya elt≈±nt, √∫jrakeresem...")
                refreshed = find_card_by_identifier(page, identifier)
                if refreshed is None:
                    record_failure("A k√°rtya nem tal√°lhat√≥ a kattint√°shoz")
                    return
                card = refreshed
                continue
            record_failure("A k√°rty√°ra kattint√°s id≈ët√∫ll√©pett")
            return

    try:
        # 1Ô∏è‚É£ Men√º megnyit√°sa
        page.wait_for_selector(MORE_OPTIONS_BUTTON_SELECTOR, timeout=15000)
        page.locator(MORE_OPTIONS_BUTTON_SELECTOR).first.click()
        print("üìÇ Men√º megnyitva...")

        # 2Ô∏è‚É£ Upscale √°llapot ellen≈ërz√©s
        disabled = page.locator(UPSCALE_MENU_DISABLED_XPATH)
        active = page.locator(UPSCALE_MENU_ACTIVE_XPATH)
        wait_with_jitter(page, WAIT_AFTER_CARD_SCROLL_MS)

        if disabled.count() > 0:
            print("üü¢ M√°r upscale-elve van, kihagyom az upscale l√©p√©st.")
            click_safe_area(page)
        else:
            print("üïê Upscale ind√≠t√°sa...")
            active.first.click()
            wait_with_jitter(page, WAIT_AFTER_MENU_INTERACTION_MS)
            click_safe_area(page)
            try:
                # v√°rjuk a HD ikon megjelen√©s√©t
                page.wait_for_selector("button:has(div:text('HD'))", timeout=UPSCALE_TIMEOUT_MS)
                print("‚úÖ Upscale k√©sz.")
            except PWTimeout:
                print("‚ö†Ô∏è  Upscale id≈ët√∫ll√©p√©s ‚Äì let√∂lt√©s upscale n√©lk√ºl.")
                upscale_failures.append(identifier)

        # 3Ô∏è‚É£ Men√º bez√°r√°sa
        wait_with_jitter(page, WAIT_AFTER_MENU_INTERACTION_MS)

        # 4Ô∏è‚É£ Let√∂lt√©s
        dl_button = page.locator(DOWNLOAD_BUTTON_SELECTOR)
        if dl_button.count() == 0:
            record_failure("Nem tal√°ltam Let√∂lt√©s gombot.")
            return
        dl_button.first.wait_for(state="visible", timeout=60000)

        with page.expect_download() as dl_info:
            dl_button.first.click()
        download = dl_info.value

        filename = download.suggested_filename or f"video_{index + 1}.mp4"
        filepath = os.path.join(DOWNLOAD_DIR, filename)

        # ha m√°r l√©tezik, t√∂r√∂lj√ºk hogy a friss p√©ld√°ny fel√ºl√≠rhassa
        if os.path.exists(filepath):
            print(f"üü° M√°r l√©tezik ({filename}), fel√ºl√≠rom.")
            try:
                os.remove(filepath)
            except OSError as remove_err:
                record_failure(f"Nem tudtam t√∂r√∂lni a r√©gi f√°jlt: {remove_err}")
                return

        download.save_as(filepath)

        # 0-b√°jtos let√∂lt√©s detekt√°l√°s
        if os.path.getsize(filepath) == 0:
            print("‚ö†Ô∏è  0 b√°jtos f√°jl ‚Äî t√∂rl√∂m √©s megpr√≥b√°lom a megnyitott k√°rty√°b√≥l let√∂lteni...")
            try:
                os.remove(filepath)
            except OSError as remove_err:
                record_failure(f"Nem tudtam t√∂r√∂lni a 0 b√°jtos f√°jlt: {remove_err}")
                return

            fallback_url = extract_video_source(page)
            if not fallback_url:
                record_failure("Nem tal√°ltam vide√≥ URL-t a k√°rtya DOM-j√°ban")
                return

            print(f"üîÅ Alternat√≠v let√∂lt√©s: {fallback_url}")

            headers = {
                "user-agent": USER_AGENT,
                "accept": "video/mp4,video/*;q=0.9,*/*;q=0.8",
                "referer": FAVORITES_URL,
            }

            try:
                r = requests.get(fallback_url, stream=True, headers=headers, timeout=60)
            except requests.RequestException as req_err:
                record_failure(f"Alternat√≠v let√∂lt√©s HTTP hiba:\n{COLOR_GRAY}{req_err}{COLOR_RESET}")
                return

            if not r.ok:
                record_failure(f"Alternat√≠v let√∂lt√©s sikertelen: HTTP {r.status_code}")
                return

            with open(filepath, "wb") as f:
                for chunk in r.iter_content(1024 * 1024):
                    f.write(chunk)

            alt_size = os.path.getsize(filepath)
            if alt_size == 0:
                record_failure("Alternat√≠v let√∂lt√©s is 0 b√°jtos maradt")
                return
            print(f"üì• Let√∂ltve alternat√≠v forr√°sb√≥l: {filename} ({alt_size} b√°jt)")
        else:
            print(f"üì• Let√∂ltve: {filename}")

    except Exception as e:
        record_failure(f"Hiba a(z) {index + 1}. vide√≥n√°l:\n{COLOR_GRAY}{e}{COLOR_RESET}")

    finally:
        # 5Ô∏è‚É£ Visszal√©p√©s
        try:
            back_button = page.locator(BACK_BUTTON_SELECTOR).first
            back_button.wait_for(state="visible", timeout=10000)
            wait_with_jitter(page, WAIT_AFTER_BACK_BUTTON_MS)
            back_button.click()
            page.wait_for_selector("div[role='listitem']", timeout=15000)
            print("‚Ü©Ô∏è  Visszat√©r√©s a gal√©ri√°ba.")
        except:
            print("‚ö†Ô∏è  Nem siker√ºlt visszal√©pni, de folytatom.")
        wait_with_jitter(page, WAIT_AFTER_BACK_BUTTON_MS)


def main():
    cookie_header = load_cookie_header(COOKIE_FILE)
    cookies = cookie_header_to_list(cookie_header, ".grok.com")

    with sync_playwright() as p:
        # Realistic user-agent (Chrome Win10)
        launch_args = [
            '--disable-blink-features=AutomationControlled',
            '--disable-infobars',
            '--disable-web-security',
            '--disable-features=IsolateOrigins,site-per-process,Translate,TranslateUI,TranslateSubFrames,LanguageDetection,RendererTranslate',
            '--disable-translate',
            '--accept-lang=hu-HU,hu,en-US,en,en-GB',
        ]
        # context = p.chromium.launch_persistent_context(
        #     user_data_dir="user-data",
        #     args=launch_args,
        #     locale="en-US"
        # )
        browser = p.chromium.launch(channel="chrome", headless=HEADLESS, args=launch_args)
        context = browser.new_context(
            accept_downloads=True,
            user_agent=USER_AGENT,
            viewport={"width": 1280, "height": 800},
            locale="en-US",
            timezone_id="Europe/Budapest",
            color_scheme="dark",
            extra_http_headers={
                "Accept-Language": "hu-HU,hu;q=0.9",
                "Sec-CH-UA": '"Google Chrome";v="141", "Chromium";v="141", "Not=A?Brand";v="24"',
                "Sec-CH-UA-Mobile": "?0",
                "Sec-CH-UA-Platform": '"Windows"',
                "Upgrade-Insecure-Requests": "1",
                "Sec-Fetch-Site": "same-origin",
                "Sec-Fetch-Mode": "navigate",
                "Sec-Fetch-User": "?1",
                "Sec-Fetch-Dest": "document",
            },
        )
        context.add_cookies(cookies)
        page = context.new_page()

        def asset_header_rewrite(route, request):
            headers = dict(request.headers)
            headers.update(ASSET_BASE_HEADERS)
            headers.setdefault("user-agent", USER_AGENT)
            route.continue_(headers=headers)

        page.route("https://assets.grok.com/*", asset_header_rewrite)

        # Remove navigator.webdriver property
        page.add_init_script(
            """
            Object.defineProperty(navigator, 'webdriver', {get: () => undefined});
            window.chrome = window.chrome || { runtime: {} };
            Object.defineProperty(navigator, 'plugins', {get: () => [1, 2, 3, 4, 5]});
            Object.defineProperty(navigator, 'languages', {get: () => ['hu-HU', 'hu']});
            Object.defineProperty(navigator, 'hardwareConcurrency', {get: () => 8});
            Object.defineProperty(navigator, 'maxTouchPoints', {get: () => 0});
        """
        )

        print("üåê Gal√©ria megnyit√°sa...")
        response = page.goto(FAVORITES_URL, wait_until="domcontentloaded")

        if response and response.status == 403:
            print("‚ùå 403 Forbidden ‚Äî val√≥sz√≠n≈±leg a cookie √©rv√©nytelen vagy a b√∂ng√©sz≈ë fingerprint blokkolt.")
            print("‚ÑπÔ∏è Pr√≥b√°ld √∫j cookie f√°jl gener√°l√°s√°t ugyanazzal a b√∂ng√©sz≈ëvel √©s user-agenttel, ahonnan a cookie sz√°rmazik.")
            return

        wait_with_jitter(page, INITIAL_PAGE_WAIT_MS)
        try:
            page.wait_for_selector("div[role='listitem']", timeout=15000)
        except PWTimeout:
            print("‚ùå Nem siker√ºlt bet√∂lteni a gal√©ri√°t ‚Äì ellen≈ërizd a cookie f√°jlt.")
            return

        cards_locator = page.locator("//div[contains(@class,'group/media-post-masonry-card')]")
        processed_ids = set()
        pending_queue = []
        pending_set = set()
        processed_count = 0
        idle_cycles = 0
        upscale_failures = []
        download_failures = []

        try:
            while True:
                card_count = cards_locator.count()
                new_cards_added = False

                for idx in range(card_count):
                    card = cards_locator.nth(idx)
                    identifier = get_card_identifier(card)
                    if not identifier or identifier == "No ID":
                        continue
                    if identifier in processed_ids or identifier in pending_set:
                        continue

                    media_info = analyze_existing_media(identifier)

                    if media_info.image_exists:
                        print(f"‚è≠Ô∏è  M√°r lementett k√©p: {media_info.image_path}")
                        processed_ids.add(identifier)
                        continue
                    elif media_info.video_exists:
                        if media_info.video_width is not None and media_info.video_width >= UPSCALE_VIDEO_WIDTH:
                            print(f"‚è≠Ô∏è  M√°r l√©tez≈ë vide√≥ ({media_info.video_width}px): {media_info.video_path}")
                            processed_ids.add(identifier)
                            continue
                        else:
                            width_txt = f"{media_info.video_width}px" if media_info.video_width else "ismeretlen"
                            print(f"‚ôªÔ∏è  L√©tez≈ë, de nem megfelel≈ë felbont√°s√∫ vide√≥ ({width_txt}): {media_info.video_path}")

                    pending_queue.append(identifier)
                    pending_set.add(identifier)
                    new_cards_added = True

                if new_cards_added:
                    idle_cycles = 0

                if not pending_queue:
                    idle_cycles += 1
                    if idle_cycles == 1:
                        print("üåÄ Nincs feldolgozand√≥ k√°rtya, g√∂rgetek tov√°bb...")
                    elif idle_cycles % MAX_IDLE_SCROLL_CYCLES == 0:
                        print(f"üåÄ Tov√°bbi g√∂rget√©s ({idle_cycles} pr√≥b√°lkoz√°s) ...")

                    wait_with_jitter(page, WAIT_IDLE_LOOP_MS)
                    scroll_to_load_more(page)
                    continue

                print(f"üî¢ H√°tral√©v≈ë megtal√°lt vide√≥k ({len(pending_queue)}): {COLOR_GRAY}{pending_queue}{COLOR_RESET}")

                identifier = pending_queue.pop(0)
                pending_set.discard(identifier)

                card = find_card_by_identifier(page, identifier)

                if card is None:
                    print("üîÑ K√°rtya nincs a DOM-ban, g√∂rget√©s lefel√©...")
                    retries = 0
                    found_card = None
                    while retries < MAX_IDLE_SCROLL_CYCLES and found_card is None:
                        scroll_to_load_more(page)
                        found_card = find_card_by_identifier(page, identifier)
                        retries += 1
                    if found_card is None:
                        print(f"‚ö†Ô∏è  {identifier} k√°rtya nem tal√°lhat√≥, kihagy√°s.")
                        processed_ids.add(identifier)
                        idle_cycles = 0
                        continue
                    card = found_card

                process_one_card(
                    context,
                    page,
                    card,
                    processed_count,
                    identifier,
                    upscale_failures,
                    download_failures,
                )
                processed_ids.add(identifier)
                processed_count += 1
                idle_cycles = 0

            print("\nüéâ K√©sz ‚Äì minden vide√≥ feldolgozva.")
        except Exception as e:
            print(f"‚ùå Folyamat megszakadt:\n\n{COLOR_GRAY}{e}{COLOR_RESET}")
            err_text = str(e).lower()
            transient_browser_errors = (
                "target closed",
                "page closed",
                "browser has been closed",
            )
            if not any(token in err_text for token in transient_browser_errors):
                raise
        finally:
            if upscale_failures:
                print("\n‚ö†Ô∏è  Az al√°bbi vide√≥k upscale n√©lk√ºl ker√ºltek let√∂lt√©sre:")
                for failed in upscale_failures:
                    print(f"   ‚Ä¢ {failed}")
            else:
                print("\n‚úÖ Minden vide√≥ sikeresen upscale-lve lett a let√∂lt√©s el≈ëtt.")

            if download_failures:
                print("\n‚ùó Let√∂lt√©si hib√°k list√°ja:")
                for ident, reason in download_failures:
                    print(f"   ‚Ä¢ {ident}: {reason}")
            else:
                print("\n‚úÖ Nem t√∂rt√©nt let√∂lt√©si hiba.")
            try:
                # context.close()
                browser.close()
            except Exception:
                pass


if __name__ == "__main__":
    main()
